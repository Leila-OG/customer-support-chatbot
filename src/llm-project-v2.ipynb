{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10148377,"sourceType":"datasetVersion","datasetId":6264704}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:15.647072Z","iopub.execute_input":"2024-12-11T22:09:15.647499Z","iopub.status.idle":"2024-12-11T22:09:15.685010Z","shell.execute_reply.started":"2024-12-11T22:09:15.647471Z","shell.execute_reply":"2024-12-11T22:09:15.684115Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/customer-support/cleaned_customer_service_dataset_ready.jsonl\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### **IMPORTS**","metadata":{}},{"cell_type":"code","source":"pip install evaluate","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Preprocessing\nimport re\nimport string\nimport shutil\nfrom sklearn.utils import resample\nfrom collections import Counter\nfrom IPython.display import FileLink\n\n# Normalisation\nimport os\nimport json\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n# import nltk\n# from nltk.corpus import stopwords\n# from nltk.stem.wordnet import WordNetLemmatizer\n\n# Processing\nimport torch\nfrom datasets import Dataset\nfrom transformers import Trainer\nfrom transformers import pipeline\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForCausalLM\nfrom transformers import TrainingArguments\nfrom transformers import AutoTokenizer, DataCollatorForLanguageModeling\n\n# Evaluation\nimport math\nimport random\nimport evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:15.686619Z","iopub.execute_input":"2024-12-11T22:09:15.686996Z","iopub.status.idle":"2024-12-11T22:09:37.082351Z","shell.execute_reply.started":"2024-12-11T22:09:15.686941Z","shell.execute_reply":"2024-12-11T22:09:37.081668Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:26:32.287230Z","iopub.execute_input":"2024-12-11T22:26:32.287580Z","iopub.status.idle":"2024-12-11T22:26:32.353670Z","shell.execute_reply.started":"2024-12-11T22:26:32.287549Z","shell.execute_reply":"2024-12-11T22:26:32.352789Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# # Df preprocessed v1\n# file_path = '/kaggle/input/customer-support/cleaned_customer_service_dataset_ready.jsonl'\n# data = pd.read_json(file_path, lines=True)\n\n# Données brutes (hugging face)\ndf = pd.read_csv(\"hf://datasets/bitext/Bitext-customer-support-llm-chatbot-training-dataset/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\")\n\n# pandas_df = pd.DataFrame(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:37.083242Z","iopub.execute_input":"2024-12-11T22:09:37.083770Z","iopub.status.idle":"2024-12-11T22:09:38.740942Z","shell.execute_reply.started":"2024-12-11T22:09:37.083734Z","shell.execute_reply":"2024-12-11T22:09:38.739920Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Nombre d'exemples par catégorie\ncategory_counts = Counter(df['category'])\nprint(category_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:38.742942Z","iopub.execute_input":"2024-12-11T22:09:38.743247Z","iopub.status.idle":"2024-12-11T22:09:38.756100Z","shell.execute_reply.started":"2024-12-11T22:09:38.743220Z","shell.execute_reply":"2024-12-11T22:09:38.755140Z"}},"outputs":[{"name":"stdout","text":"Counter({'ACCOUNT': 5986, 'ORDER': 3988, 'REFUND': 2992, 'INVOICE': 1999, 'CONTACT': 1999, 'PAYMENT': 1998, 'FEEDBACK': 1997, 'DELIVERY': 1994, 'SHIPPING': 1970, 'SUBSCRIPTION': 999, 'CANCEL': 950})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:38.756999Z","iopub.execute_input":"2024-12-11T22:09:38.757209Z","iopub.status.idle":"2024-12-11T22:09:38.768951Z","shell.execute_reply.started":"2024-12-11T22:09:38.757187Z","shell.execute_reply":"2024-12-11T22:09:38.768040Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['flags', 'instruction', 'category', 'intent', 'response'], dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"### **STRATIFIED SAMPLING**\n> Echantillonnage strat des données","metadata":{}},{"cell_type":"code","source":"# Nombre total d'exemples souhaités\ntotal_samples = 2000\n\n# Proportion d'exemples par catégorie\ncategory_counts = df['category'].value_counts()\ncategory_proportions = (category_counts / category_counts.sum())\nprint(f\"proportion pour chaque catégorie : {category_proportions.values}\")\n\n# Nombre d'exemples pour chaque catégorie\nsamples_per_category = (category_proportions * total_samples).astype(int)\n\n# Échantillonnage\nbalanced_df = pd.DataFrame()\nfor category, n_samples in samples_per_category.items():\n    category_data = df[df['category'] == category]\n    sampled_data = category_data.sample(n=min(n_samples, len(category_data)), random_state=42)\n    balanced_df = pd.concat([balanced_df, sampled_data])\n\nbalanced_df = shuffle(balanced_df, random_state=42)\nprint(balanced_df['category'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:43.997737Z","iopub.execute_input":"2024-12-11T22:09:43.998083Z","iopub.status.idle":"2024-12-11T22:09:44.055804Z","shell.execute_reply.started":"2024-12-11T22:09:43.998053Z","shell.execute_reply":"2024-12-11T22:09:44.054988Z"}},"outputs":[{"name":"stdout","text":"proportion pour chaque catégorie : [0.22275975 0.14840726 0.11134266 0.0743897  0.0743897  0.07435249\n 0.07431527 0.07420363 0.07331051 0.03717624 0.03535278]\ncategory\nACCOUNT         445\nORDER           296\nREFUND          222\nDELIVERY        148\nFEEDBACK        148\nINVOICE         148\nPAYMENT         148\nCONTACT         148\nSHIPPING        146\nSUBSCRIPTION     74\nCANCEL           70\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Sauvegarder les données réduites\nbalanced_df.to_json('reduced_dataset.jsonl', orient='records', lines=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:09:47.449507Z","iopub.execute_input":"2024-12-11T22:09:47.449865Z","iopub.status.idle":"2024-12-11T22:09:47.470447Z","shell.execute_reply.started":"2024-12-11T22:09:47.449832Z","shell.execute_reply":"2024-12-11T22:09:47.469661Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"balanced_df.query(\"category == 'ORDER'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:02.557363Z","iopub.execute_input":"2024-12-11T22:10:02.557725Z","iopub.status.idle":"2024-12-11T22:10:02.578211Z","shell.execute_reply.started":"2024-12-11T22:10:02.557676Z","shell.execute_reply":"2024-12-11T22:10:02.577420Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"       flags                                        instruction category  \\\n70        BZ  I need assistancde cancelling order {{Order Nu...    ORDER   \n25107    BKL  checking purchase {{Order Number}} current status    ORDER   \n1731      BL        I need to correct purchase {{Order Number}}    ORDER   \n1001    BCIQ  need to change order {{Order Number}} how to d...    ORDER   \n25130    BIQ  where do i check the status of order {{Order N...    ORDER   \n...      ...                                                ...      ...   \n1552    BLMQ  i need help to delete some products from order...    ORDER   \n25197     BK                              check status of order    ORDER   \n1798   BILMQ  how do i remove several articles from order {{...    ORDER   \n1003      BK            remove item from order {{Order Number}}    ORDER   \n1461      BL  help me to change a product of purchase {{Orde...    ORDER   \n\n             intent                                           response  \n70     cancel_order  I've noticed that you require assistance with ...  \n25107   track_order  Thanks for getting in touch! I grasp that you ...  \n1731   change_order  Thank you for informing us about the need to c...  \n1001   change_order  We've received your message to us for assistan...  \n25130   track_order  I hear you! I'm following you that you would l...  \n...             ...                                                ...  \n1552   change_order  We understand that you would like assistance i...  \n25197   track_order  Thank you for reaching out! I'm here to help y...  \n1798   change_order  We're here for you to us for assistance with r...  \n1003   change_order  I've decoded that you need assistance with rem...  \n1461   change_order  Thank you for trusting to us for assistance wi...  \n\n[296 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flags</th>\n      <th>instruction</th>\n      <th>category</th>\n      <th>intent</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>70</th>\n      <td>BZ</td>\n      <td>I need assistancde cancelling order {{Order Nu...</td>\n      <td>ORDER</td>\n      <td>cancel_order</td>\n      <td>I've noticed that you require assistance with ...</td>\n    </tr>\n    <tr>\n      <th>25107</th>\n      <td>BKL</td>\n      <td>checking purchase {{Order Number}} current status</td>\n      <td>ORDER</td>\n      <td>track_order</td>\n      <td>Thanks for getting in touch! I grasp that you ...</td>\n    </tr>\n    <tr>\n      <th>1731</th>\n      <td>BL</td>\n      <td>I need to correct purchase {{Order Number}}</td>\n      <td>ORDER</td>\n      <td>change_order</td>\n      <td>Thank you for informing us about the need to c...</td>\n    </tr>\n    <tr>\n      <th>1001</th>\n      <td>BCIQ</td>\n      <td>need to change order {{Order Number}} how to d...</td>\n      <td>ORDER</td>\n      <td>change_order</td>\n      <td>We've received your message to us for assistan...</td>\n    </tr>\n    <tr>\n      <th>25130</th>\n      <td>BIQ</td>\n      <td>where do i check the status of order {{Order N...</td>\n      <td>ORDER</td>\n      <td>track_order</td>\n      <td>I hear you! I'm following you that you would l...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1552</th>\n      <td>BLMQ</td>\n      <td>i need help to delete some products from order...</td>\n      <td>ORDER</td>\n      <td>change_order</td>\n      <td>We understand that you would like assistance i...</td>\n    </tr>\n    <tr>\n      <th>25197</th>\n      <td>BK</td>\n      <td>check status of order</td>\n      <td>ORDER</td>\n      <td>track_order</td>\n      <td>Thank you for reaching out! I'm here to help y...</td>\n    </tr>\n    <tr>\n      <th>1798</th>\n      <td>BILMQ</td>\n      <td>how do i remove several articles from order {{...</td>\n      <td>ORDER</td>\n      <td>change_order</td>\n      <td>We're here for you to us for assistance with r...</td>\n    </tr>\n    <tr>\n      <th>1003</th>\n      <td>BK</td>\n      <td>remove item from order {{Order Number}}</td>\n      <td>ORDER</td>\n      <td>change_order</td>\n      <td>I've decoded that you need assistance with rem...</td>\n    </tr>\n    <tr>\n      <th>1461</th>\n      <td>BL</td>\n      <td>help me to change a product of purchase {{Orde...</td>\n      <td>ORDER</td>\n      <td>change_order</td>\n      <td>Thank you for trusting to us for assistance wi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>296 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"balanced_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:06.950178Z","iopub.execute_input":"2024-12-11T22:10:06.951115Z","iopub.status.idle":"2024-12-11T22:10:06.957038Z","shell.execute_reply.started":"2024-12-11T22:10:06.951063Z","shell.execute_reply":"2024-12-11T22:10:06.956163Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(1993, 5)"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"### **PREPROCESSING**","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = text.strip()  # Supprime les espaces superflus\n    text = re.sub(r'\\s+', ' ', text)  # Remplace plusieurs espaces par un seul\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:08.862270Z","iopub.execute_input":"2024-12-11T22:10:08.862630Z","iopub.status.idle":"2024-12-11T22:10:08.867399Z","shell.execute_reply.started":"2024-12-11T22:10:08.862595Z","shell.execute_reply":"2024-12-11T22:10:08.866421Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Drop NaN\nbalanced_df = balanced_df.dropna(subset=[\"instruction\", \"response\"])\n\n# Clean\nbalanced_df[\"instruction\"] = balanced_df[\"instruction\"].apply(clean_text)\nbalanced_df[\"response\"] = balanced_df[\"response\"].apply(clean_text)\nbalanced_df[\"text\"] = balanced_df[\"category\"] + \": \" + balanced_df[\"instruction\"] + \" \" + balanced_df[\"response\"]  # structure les données","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:11.237407Z","iopub.execute_input":"2024-12-11T22:10:11.237943Z","iopub.status.idle":"2024-12-11T22:10:11.329387Z","shell.execute_reply.started":"2024-12-11T22:10:11.237902Z","shell.execute_reply":"2024-12-11T22:10:11.328760Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# balanced_df['text'].head(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T21:46:41.941745Z","iopub.execute_input":"2024-12-11T21:46:41.942681Z","iopub.status.idle":"2024-12-11T21:46:41.950774Z","shell.execute_reply.started":"2024-12-11T21:46:41.942617Z","shell.execute_reply":"2024-12-11T21:46:41.949613Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"25957    REFUND: I'm waiting for a reimbursement of 120...\nName: text, dtype: object"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"balanced_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T21:47:40.155640Z","iopub.execute_input":"2024-12-11T21:47:40.156091Z","iopub.status.idle":"2024-12-11T21:47:40.171782Z","shell.execute_reply.started":"2024-12-11T21:47:40.156053Z","shell.execute_reply":"2024-12-11T21:47:40.170310Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"        flags                                        instruction  category  \\\n25957    BLQZ     I'm waiting for a reimbursement of 1200dollars    REFUND   \n12854  BCILMQ  wanna see what shipment methods i can choose h...  DELIVERY   \n20492    BILQ    what do i have to do to retrieve my account pin   ACCOUNT   \n12385   BCILP  I have to see the shipping options, could I ge...  DELIVERY   \n26829    BLQW  I'm waiting for a goddamn compensation of {{Re...    REFUND   \n...       ...                                                ...       ...   \n9426      BLZ      I don't know how to speak with a humnan agent   CONTACT   \n18153    BLMZ         help to solve an error withonline payments   PAYMENT   \n26107     BLQ  i expect a reimbursement of {{Currency Symbol}...    REFUND   \n7800       BL  I call to lodge a customer complaint against y...  FEEDBACK   \n8230      BIL  can I see at what time customer service availa...   CONTACT   \n\n                         intent  \\\n25957              track_refund   \n12854          delivery_options   \n20492          recover_password   \n12385          delivery_options   \n26829              track_refund   \n...                         ...   \n9426        contact_human_agent   \n18153             payment_issue   \n26107              track_refund   \n7800                  complaint   \n8230   contact_customer_service   \n\n                                                response  \\\n25957  I'm fully aware of how important it is for you...   \n12854  Of course! I'm thrilled to assist you in explo...   \n20492  I'm on your side your concern about retrieving...   \n12385  I'll take care of it! I'm here to guide you th...   \n26829  I can relate to the understanding that you are...   \n...                                                  ...   \n9426   Thank you for trusting us! I'm fully aware of ...   \n18153  I appreciate you reaching out for assistance i...   \n26107  We understand the importance of your expectati...   \n7800   I'm sorry to hear that you're calling to lodge...   \n8230   Thank you for contacting! I certainly recogniz...   \n\n                                                    text  \n25957  REFUND: I'm waiting for a reimbursement of 120...  \n12854  DELIVERY: wanna see what shipment methods i ca...  \n20492  ACCOUNT: what do i have to do to retrieve my a...  \n12385  DELIVERY: I have to see the shipping options, ...  \n26829  REFUND: I'm waiting for a goddamn compensation...  \n...                                                  ...  \n9426   CONTACT: I don't know how to speak with a humn...  \n18153  PAYMENT: help to solve an error withonline pay...  \n26107  REFUND: i expect a reimbursement of {{Currency...  \n7800   FEEDBACK: I call to lodge a customer complaint...  \n8230   CONTACT: can I see at what time customer servi...  \n\n[1993 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flags</th>\n      <th>instruction</th>\n      <th>category</th>\n      <th>intent</th>\n      <th>response</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>25957</th>\n      <td>BLQZ</td>\n      <td>I'm waiting for a reimbursement of 1200dollars</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>I'm fully aware of how important it is for you...</td>\n      <td>REFUND: I'm waiting for a reimbursement of 120...</td>\n    </tr>\n    <tr>\n      <th>12854</th>\n      <td>BCILMQ</td>\n      <td>wanna see what shipment methods i can choose h...</td>\n      <td>DELIVERY</td>\n      <td>delivery_options</td>\n      <td>Of course! I'm thrilled to assist you in explo...</td>\n      <td>DELIVERY: wanna see what shipment methods i ca...</td>\n    </tr>\n    <tr>\n      <th>20492</th>\n      <td>BILQ</td>\n      <td>what do i have to do to retrieve my account pin</td>\n      <td>ACCOUNT</td>\n      <td>recover_password</td>\n      <td>I'm on your side your concern about retrieving...</td>\n      <td>ACCOUNT: what do i have to do to retrieve my a...</td>\n    </tr>\n    <tr>\n      <th>12385</th>\n      <td>BCILP</td>\n      <td>I have to see the shipping options, could I ge...</td>\n      <td>DELIVERY</td>\n      <td>delivery_options</td>\n      <td>I'll take care of it! I'm here to guide you th...</td>\n      <td>DELIVERY: I have to see the shipping options, ...</td>\n    </tr>\n    <tr>\n      <th>26829</th>\n      <td>BLQW</td>\n      <td>I'm waiting for a goddamn compensation of {{Re...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>I can relate to the understanding that you are...</td>\n      <td>REFUND: I'm waiting for a goddamn compensation...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9426</th>\n      <td>BLZ</td>\n      <td>I don't know how to speak with a humnan agent</td>\n      <td>CONTACT</td>\n      <td>contact_human_agent</td>\n      <td>Thank you for trusting us! I'm fully aware of ...</td>\n      <td>CONTACT: I don't know how to speak with a humn...</td>\n    </tr>\n    <tr>\n      <th>18153</th>\n      <td>BLMZ</td>\n      <td>help to solve an error withonline payments</td>\n      <td>PAYMENT</td>\n      <td>payment_issue</td>\n      <td>I appreciate you reaching out for assistance i...</td>\n      <td>PAYMENT: help to solve an error withonline pay...</td>\n    </tr>\n    <tr>\n      <th>26107</th>\n      <td>BLQ</td>\n      <td>i expect a reimbursement of {{Currency Symbol}...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>We understand the importance of your expectati...</td>\n      <td>REFUND: i expect a reimbursement of {{Currency...</td>\n    </tr>\n    <tr>\n      <th>7800</th>\n      <td>BL</td>\n      <td>I call to lodge a customer complaint against y...</td>\n      <td>FEEDBACK</td>\n      <td>complaint</td>\n      <td>I'm sorry to hear that you're calling to lodge...</td>\n      <td>FEEDBACK: I call to lodge a customer complaint...</td>\n    </tr>\n    <tr>\n      <th>8230</th>\n      <td>BIL</td>\n      <td>can I see at what time customer service availa...</td>\n      <td>CONTACT</td>\n      <td>contact_customer_service</td>\n      <td>Thank you for contacting! I certainly recogniz...</td>\n      <td>CONTACT: can I see at what time customer servi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1993 rows × 6 columns</p>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"markdown","source":"### **TRAIN - TEST SPLIT**","metadata":{}},{"cell_type":"code","source":"# Diviser en ensembles train/val/test\ntrain_data, test_data = train_test_split(balanced_df, test_size=0.2, stratify=balanced_df[\"category\"], random_state=42)\ntrain_data, val_data = train_test_split(train_data, test_size=0.1, stratify=train_data[\"category\"], random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:16.957422Z","iopub.execute_input":"2024-12-11T22:10:16.957813Z","iopub.status.idle":"2024-12-11T22:10:16.970816Z","shell.execute_reply.started":"2024-12-11T22:10:16.957779Z","shell.execute_reply":"2024-12-11T22:10:16.969892Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### **TOKENIZATION & ADJUSTMENT**","metadata":{}},{"cell_type":"code","source":"# Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")  \n\n# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n\n# Utilise le token de fin de séquence (eos_token) comme token de padding\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:20.177087Z","iopub.execute_input":"2024-12-11T22:10:20.177686Z","iopub.status.idle":"2024-12-11T22:10:22.816464Z","shell.execute_reply.started":"2024-12-11T22:10:20.177648Z","shell.execute_reply":"2024-12-11T22:10:22.815761Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b33bb17c9b741a4988a9799c3ae11d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4772b81cfeb40e68888792c0551b9a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc99f952bdab467d9967e7c7cf37bf14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a801b2b1210d41bf82d4c5f89d3a6c7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e39e495efb4f438b87cf53e61fe0298c"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"**V1**","metadata":{}},{"cell_type":"code","source":"# def preprocess_data(examples):\n#     input_texts = examples[\"instruction\"]\n#     output_texts = examples[\"response\"]\n#     combined_texts = [f\"{input_text}{output_text}\" for input_text, output_text in zip(input_texts, output_texts)]\n\n#     # Tokenisation\n#     tokenized = tokenizer(\n#         combined_texts,\n#         truncation=True,\n#         padding=\"max_length\",\n#         max_length=256,      # a ajuster \n#         return_tensors=\"pt\"\n#     )\n#     return tokenized","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:31.624085Z","iopub.execute_input":"2024-12-11T22:10:31.624432Z","iopub.status.idle":"2024-12-11T22:10:31.628760Z","shell.execute_reply.started":"2024-12-11T22:10:31.624391Z","shell.execute_reply":"2024-12-11T22:10:31.627780Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# # Conversion en Dataset Hugging face\n# dataset = Dataset.from_pandas(balanced_df)\n\n# # Prétraiter le dataset\n# tokenized_dataset = dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:34.322407Z","iopub.execute_input":"2024-12-11T22:10:34.322835Z","iopub.status.idle":"2024-12-11T22:10:34.326592Z","shell.execute_reply.started":"2024-12-11T22:10:34.322799Z","shell.execute_reply":"2024-12-11T22:10:34.325622Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# tokenized_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:37.641973Z","iopub.execute_input":"2024-12-11T22:10:37.642313Z","iopub.status.idle":"2024-12-11T22:10:37.646538Z","shell.execute_reply.started":"2024-12-11T22:10:37.642280Z","shell.execute_reply":"2024-12-11T22:10:37.645564Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"**V2**","metadata":{}},{"cell_type":"code","source":"# Tokenisation\ntrain_encodings = tokenizer(list(train_data[\"text\"]), truncation=True, padding=True, max_length=256)\nval_encodings = tokenizer(list(val_data[\"text\"]), truncation=True, padding=True, max_length=256)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:39.607293Z","iopub.execute_input":"2024-12-11T22:10:39.607637Z","iopub.status.idle":"2024-12-11T22:10:39.975781Z","shell.execute_reply.started":"2024-12-11T22:10:39.607604Z","shell.execute_reply":"2024-12-11T22:10:39.974833Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# train_encodings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:40.637007Z","iopub.execute_input":"2024-12-11T22:10:40.637827Z","iopub.status.idle":"2024-12-11T22:10:40.641762Z","shell.execute_reply.started":"2024-12-11T22:10:40.637787Z","shell.execute_reply":"2024-12-11T22:10:40.640673Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# DataCollator\ndata_collator = DataCollatorForLanguageModeling(\n    tokenizer=tokenizer,\n    mlm=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:41.792211Z","iopub.execute_input":"2024-12-11T22:10:41.792930Z","iopub.status.idle":"2024-12-11T22:10:41.796753Z","shell.execute_reply.started":"2024-12-11T22:10:41.792893Z","shell.execute_reply":"2024-12-11T22:10:41.795894Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"### **PROCESSING**","metadata":{}},{"cell_type":"code","source":"model_name = \"EleutherAI/gpt-neo-125M\"  # Modèle plus petit\nmodel = AutoModelForCausalLM.from_pretrained(model_name)\n\n# model = AutoModelForCausalLM.from_pretrained(\"gpt2\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:10:44.357590Z","iopub.execute_input":"2024-12-11T22:10:44.357969Z","iopub.status.idle":"2024-12-11T22:10:48.028136Z","shell.execute_reply.started":"2024-12-11T22:10:44.357936Z","shell.execute_reply":"2024-12-11T22:10:48.027299Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8c51f93d6ee4ef3a288d9269512aa11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/526M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84dc3de6ca734a1a8ca956017b612192"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b48cb9f14aff4d67b374dc948ba2fc93"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Utilisation du GPU pour accélérer l'entrainement\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:11:14.363367Z","iopub.execute_input":"2024-12-11T22:11:14.364205Z","iopub.status.idle":"2024-12-11T22:11:14.864830Z","shell.execute_reply.started":"2024-12-11T22:11:14.364168Z","shell.execute_reply":"2024-12-11T22:11:14.863906Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"GPTNeoForCausalLM(\n  (transformer): GPTNeoModel(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(2048, 768)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPTNeoBlock(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTNeoAttention(\n          (attention): GPTNeoSelfAttention(\n            (attn_dropout): Dropout(p=0.0, inplace=False)\n            (resid_dropout): Dropout(p=0.0, inplace=False)\n            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n            (v_proj): Linear(in_features=768, out_features=768, bias=False)\n            (q_proj): Linear(in_features=768, out_features=768, bias=False)\n            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n          )\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPTNeoMLP(\n          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# Transforme les données en Dataset Hugging Face\ntrain_dataset = Dataset.from_dict({\n    \"input_ids\": train_encodings[\"input_ids\"],\n    \"attention_mask\": train_encodings[\"attention_mask\"],\n    \"labels\": train_encodings[\"input_ids\"]  # Les labels sont les mêmes que les input_ids pour causal LM\n})\n\nval_dataset = Dataset.from_dict({\n    \"input_ids\": val_encodings[\"input_ids\"],\n    \"attention_mask\": val_encodings[\"attention_mask\"],\n    \"labels\": val_encodings[\"input_ids\"]\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:11:26.592863Z","iopub.execute_input":"2024-12-11T22:11:26.593200Z","iopub.status.idle":"2024-12-11T22:11:26.859342Z","shell.execute_reply.started":"2024-12-11T22:11:26.593169Z","shell.execute_reply":"2024-12-11T22:11:26.858448Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Hyperparams de l'entrainement\ntraining_args = TrainingArguments(\n    output_dir=\"./gpt_neo_ft_2\",  # Sauvegarde du modèle\n    evaluation_strategy=\"no\",  # Évaluation à la fin de chaque epoch / sinon \"no\"\n    learning_rate=5e-5,           \n    per_device_train_batch_size=4,  # Taille des batches d'entraînement\n    per_device_eval_batch_size=4,   # Taille des batches d'évaluation\n    num_train_epochs=3,          \n    weight_decay=0.01,           # Régularisation L2\n    save_strategy=\"no\",          # Sauvegarde du modèle à chaque epoch\n    logging_dir=\"./logs\",        # Dossier pour les logs\n    logging_steps=10,            # Intervalle de logging\n    # save_total_limit=2,          # Sauvegarder seulement les 2 derniers checkpoints\n    # load_best_model_at_end=True, # Charger le meilleur modèle basé sur la métrique d'évaluation\n    fp16=True,                   # Utilisation de la précision mixte pour accélérer l'entraînement sur GPU\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:11:29.677182Z","iopub.execute_input":"2024-12-11T22:11:29.677512Z","iopub.status.idle":"2024-12-11T22:11:29.714895Z","shell.execute_reply.started":"2024-12-11T22:11:29.677480Z","shell.execute_reply":"2024-12-11T22:11:29.713783Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=data_collator,  # pour gérer le padding\n    tokenizer=tokenizer,         \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:11:31.883464Z","iopub.execute_input":"2024-12-11T22:11:31.884287Z","iopub.status.idle":"2024-12-11T22:11:33.260300Z","shell.execute_reply.started":"2024-12-11T22:11:31.884247Z","shell.execute_reply":"2024-12-11T22:11:33.259607Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2534229619.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:11:33.763928Z","iopub.execute_input":"2024-12-11T22:11:33.764256Z","iopub.status.idle":"2024-12-11T22:15:46.071017Z","shell.execute_reply.started":"2024-12-11T22:11:33.764226Z","shell.execute_reply":"2024-12-11T22:15:46.070324Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241211_221144-b3coi56f</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/leila-othenin-efrei/huggingface/runs/b3coi56f' target=\"_blank\">./gpt_neo_ft_2</a></strong> to <a href='https://wandb.ai/leila-othenin-efrei/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/leila-othenin-efrei/huggingface' target=\"_blank\">https://wandb.ai/leila-othenin-efrei/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/leila-othenin-efrei/huggingface/runs/b3coi56f' target=\"_blank\">https://wandb.ai/leila-othenin-efrei/huggingface/runs/b3coi56f</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [540/540 03:57, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.289400</td>\n      <td>1.270850</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.077100</td>\n      <td>1.159278</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.021200</td>\n      <td>1.136602</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=540, training_loss=1.2514916208055284, metrics={'train_runtime': 251.9816, 'train_samples_per_second': 17.073, 'train_steps_per_second': 2.143, 'total_flos': 561856466386944.0, 'train_loss': 1.2514916208055284, 'epoch': 3.0})"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"### **EVALUATION**","metadata":{}},{"cell_type":"code","source":"eval_results = trainer.evaluate()\nprint(f\"Evaluation Results: {eval_results}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:17:29.282899Z","iopub.execute_input":"2024-12-11T22:17:29.283288Z","iopub.status.idle":"2024-12-11T22:17:32.653303Z","shell.execute_reply.started":"2024-12-11T22:17:29.283253Z","shell.execute_reply":"2024-12-11T22:17:32.652323Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [20/20 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation Results: {'eval_loss': 1.1366021633148193, 'eval_runtime': 3.3593, 'eval_samples_per_second': 47.629, 'eval_steps_per_second': 5.954, 'epoch': 3.0}\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"perplexity = math.exp(eval_results[\"eval_loss\"])\nprint(f\"Perplexity: {perplexity}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:18:04.323178Z","iopub.execute_input":"2024-12-11T22:18:04.324020Z","iopub.status.idle":"2024-12-11T22:18:04.330391Z","shell.execute_reply.started":"2024-12-11T22:18:04.323983Z","shell.execute_reply":"2024-12-11T22:18:04.329475Z"}},"outputs":[{"name":"stdout","text":"Perplexity: 3.1161621462331133\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"### **SAVE THE MODEL**","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"./gpt_neo_ft_2\")\ntokenizer.save_pretrained(\"./gpt_neo_ft_2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:21:32.617429Z","iopub.execute_input":"2024-12-11T22:21:32.617760Z","iopub.status.idle":"2024-12-11T22:21:33.788539Z","shell.execute_reply.started":"2024-12-11T22:21:32.617730Z","shell.execute_reply":"2024-12-11T22:21:33.787654Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"('./gpt_neo_ft_2/tokenizer_config.json',\n './gpt_neo_ft_2/special_tokens_map.json',\n './gpt_neo_ft_2/vocab.json',\n './gpt_neo_ft_2/merges.txt',\n './gpt_neo_ft_2/added_tokens.json',\n './gpt_neo_ft_2/tokenizer.json')"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"%cd /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:27:25.432458Z","iopub.execute_input":"2024-12-11T22:27:25.432826Z","iopub.status.idle":"2024-12-11T22:27:25.439992Z","shell.execute_reply.started":"2024-12-11T22:27:25.432794Z","shell.execute_reply":"2024-12-11T22:27:25.438947Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Crée un fichier zip contenant tous les fichiers du dossier fine_tuned_model\noutput_dir = \"./gpt_neo_ft_2\"\n\nshutil.make_archive(\"gpt_neo_ft_2\", 'zip', output_dir)\n\nFileLink(r'gpt_neo_ft_2.zip')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:28:01.443019Z","iopub.execute_input":"2024-12-11T22:28:01.443380Z","iopub.status.idle":"2024-12-11T22:28:27.292763Z","shell.execute_reply.started":"2024-12-11T22:28:01.443346Z","shell.execute_reply":"2024-12-11T22:28:27.291891Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/gpt_neo_ft_2.zip","text/html":"<a href='gpt_neo_ft_2.zip' target='_blank'>gpt_neo_ft_2.zip</a><br>"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"# Libère la mémoire GPU inutilisée\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:48:58.743956Z","iopub.execute_input":"2024-12-11T22:48:58.744313Z","iopub.status.idle":"2024-12-11T22:48:58.951403Z","shell.execute_reply.started":"2024-12-11T22:48:58.744278Z","shell.execute_reply":"2024-12-11T22:48:58.950491Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"### **TEST**","metadata":{}},{"cell_type":"markdown","source":"**V1**","metadata":{}},{"cell_type":"code","source":"# Charge le modèle fine-tuné\ngenerator = pipeline(\"text-generation\", model=\"./gpt_neo_ft_2\", tokenizer=tokenizer)\n\n# Générer une réponse\nprompt = \"I need assistance with my order.\"\nresponse = generator(prompt, max_length=50, num_return_sequences=1)\nprint(response[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:28:48.318111Z","iopub.execute_input":"2024-12-11T22:28:48.318471Z","iopub.status.idle":"2024-12-11T22:28:50.079585Z","shell.execute_reply.started":"2024-12-11T22:28:48.318437Z","shell.execute_reply":"2024-12-11T22:28:50.078691Z"}},"outputs":[{"name":"stderr","text":"Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"},{"name":"stdout","text":"I need assistance with my order. I'm here to assist you with the necessary steps to make your order from {{Order Number}}. To get started, could you please provide me with the specific details of your order? This will allow me to locate\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"**V2**","metadata":{}},{"cell_type":"code","source":"def chatbot_response(question, model, tokenizer, device):\n    \"\"\"\n    Génère une réponse à une question en utilisant le modèle fine-tuné.\n    \n    Args:\n        question (str): La question à poser au chatbot.\n        model: Le modèle fine-tuné.\n        tokenizer: Le tokenizer utilisé avec le modèle.\n        device: L'appareil utilisé pour l'inférence (GPU ou CPU).\n\n    Returns:\n        str: La réponse générée par le modèle.\n    \"\"\"\n    input_text = f\"question: {question}\"\n    input_ids = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=256).input_ids.to(device)\n\n    # Génère la réponse avec le modèle\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=input_ids,\n            max_new_tokens=100,     # Nombre maximum de tokens générés\n            # max_length=100,         # Longueur maximale de la réponse\n            num_beams=7,            # Beam search pour générer des réponses de meilleure qualité\n            early_stopping=True,    # Arrêter si toutes les séquences sont complètes\n            do_sample=True,         # Ajouter de la diversité dans la génération\n            temperature=0.7,        # Contrôle de la probabilité pour la génération\n            top_k=50,               # Limite des prédictions au top-k tokens\n            top_p=0.9,              # Nucleus sampling (p-probability mass)\n            repetition_penalty=1.2  # Réduction des répétitions dans la génération\n        )\n\n    # Décode les tokens en texte\n    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:18:45.847516Z","iopub.execute_input":"2024-12-11T23:18:45.848129Z","iopub.status.idle":"2024-12-11T23:18:45.854961Z","shell.execute_reply.started":"2024-12-11T23:18:45.848090Z","shell.execute_reply":"2024-12-11T23:18:45.854089Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# Exemple de question pour le chatbot\nquestion = \"How to change delivery address?\"\nresponse = chatbot_response(question, model, tokenizer, device)\nprint(\"Chatbot response:\", response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T22:57:51.542871Z","iopub.execute_input":"2024-12-11T22:57:51.543561Z","iopub.status.idle":"2024-12-11T22:57:53.066959Z","shell.execute_reply.started":"2024-12-11T22:57:51.543526Z","shell.execute_reply":"2024-12-11T22:57:53.065984Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Chatbot response: question: How to change delivery address? Thank you for reaching out! I'm here to guide you through the process of changing your delivery address. To change your delivery address, you can follow these steps: 1. Log in to your account on our website. 2. Navigate to the 'My Account' or 'Profile' section. 3. Look for the 'Shipping Addresses' or similar option. 4. Click on the 'Add a New Address' or 'Edit Shipping Addresses'\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"### **VISUALIZE METRICS**","metadata":{}},{"cell_type":"code","source":"pip install rouge_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install bert_score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_comparison_responses(eval_dataset, model, tokenizer, device, num_samples=5):\n    \"\"\"\n    Génère des réponses pour des échantillons aléatoires et compare avec les réponses réelles.\n\n    Args:\n        eval_dataset (Dataset): Dataset contenant les questions et réponses réelles.\n        model: Le modèle fine-tuné.\n        tokenizer: Le tokenizer utilisé avec le modèle.\n        device: L'appareil utilisé pour l'inférence (GPU ou CPU).\n        num_samples (int): Nombre d'échantillons à évaluer.\n\n    Returns:\n        pd.DataFrame: Un tableau comparant les réponses réelles et prédictions.\n    \"\"\"\n    random_indices = random.sample(range(len(eval_dataset)), num_samples)\n    results = []\n\n    bleu_metric = evaluate.load(\"bleu\")\n    rouge_metric = evaluate.load(\"rouge\")\n    bertscore_metric = evaluate.load(\"bertscore\")\n\n    for idx in random_indices:\n        sample = eval_dataset[idx]\n        \n        # Décoder la question (input_ids) et la réponse réelle (labels)\n        question = tokenizer.decode(sample[\"input_ids\"], skip_special_tokens=True)\n        true_response = tokenizer.decode(sample[\"labels\"], skip_special_tokens=True)\n        \n        # Générer la réponse prédite\n        predicted_response = chatbot_response(question, model, tokenizer, device)\n\n        # Calcul des métriques\n        decoded_preds = [predicted_response.strip()]\n        decoded_labels = [[true_response.strip()]]\n\n        bleu = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)[\"bleu\"]\n\n        rouge = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n\n        bertscore = bertscore_metric.compute(predictions=decoded_preds, references=decoded_labels, lang=\"en\")[\"f1\"]\n\n        results.append({\n            \"question\": question,\n            \"true_response\": true_response,\n            \"predicted_response\": predicted_response,\n            \"bleu\": bleu,\n            \"rouge\": rouge,\n            \"bertscore\": bertscore[0]\n        })\n\n    df = pd.DataFrame(results)\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:15:14.328052Z","iopub.execute_input":"2024-12-11T23:15:14.328757Z","iopub.status.idle":"2024-12-11T23:15:14.336553Z","shell.execute_reply.started":"2024-12-11T23:15:14.328694Z","shell.execute_reply":"2024-12-11T23:15:14.335696Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Génère un rapport comparatif pour des échantillons aléatoires\nnum_samples = 5  \ndf_res = generate_comparison_responses(val_dataset, model, tokenizer, device, num_samples=num_samples)\n\n# Afficher les résultats\npd.set_option('display.max_colwidth', None)\nprint(df_res.head(num_samples))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:18:54.998526Z","iopub.execute_input":"2024-12-11T23:18:54.999356Z","iopub.status.idle":"2024-12-11T23:19:07.493497Z","shell.execute_reply.started":"2024-12-11T23:18:54.999308Z","shell.execute_reply":"2024-12-11T23:19:07.491897Z"}},"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nSome weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\nThe attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      question  \\\n0                                                                                                                                                                                                                                                                                                                           DELIVERY: can ya show me when my purchase is gonna arrive Positively! We understand your curiosity about the expected arrival time of your purchase. To assist you promptly, could you please provide the {{Order Number}} or {{Tracking Number}} associated with your purchase? With this information, we'll be able to provide you with an accurate estimate of the delivery date. Your patience is greatly appreciated as we work to provide you with the information you need.   \n1                                                                                                                       FEEDBACK: I'm not happy with ur work how do i make a claim I'm aware that you're feeling dissatisfied with our work, and I apologize for any inconvenience caused. Your feedback is crucial to us, and I want to ensure that your concern is addressed promptly and effectively. To make a claim, I recommend reaching out to our customer support team. They are available {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. They will guide you through the process and provide the necessary assistance. We appreciate your patience and understanding and look forward to resolving this matter for you.   \n2                                                                                                                                                                                                                                                                                                                                                           ORDER: I don't know how I can order some of your product We're here to help and expressing your interest in ordering some of our products! I'm here to guide you through the process step by step, so you can easily place your order. To get started, could you please provide me with the specific product(s) you would like to order? Once I have that information, I'll be able to assist you further and ensure a smooth ordering experience.   \n3                                                                                                                                   CONTACT: I need help chatting with an operator Your message means a lot! I'm aligned with the idea that you're seeking assistance with chatting with an operator. Our team of dedicated operators is here to help you with any questions or concerns you may have. To connect you with the right operator, could you please provide some more details about the specific topic or issue you need assistance with? This will enable us to ensure that you receive the most accurate and personalized support. While we gather the necessary information, please know that we appreciate your patience and are committed to providing you with the best possible assistance.   \n4  PAYMENT: can you tell me what payment options are available? I'll do my best! I'd be happy to provide you with information on our available payment options. At our company, we strive to offer a wide variety of payment methods to ensure convenience for our valued customers. Currently, we accept major credit and debit cards such as Visa, Mastercard, and American Express. We also offer the option to pay through popular online platforms like PayPal, Apple Pay, and Google Wallet. Additionally, we provide the facility for bank transfers, allowing you to make direct payments from your bank account. If you have any further questions or need assistance with any specific payment method, feel free to ask. We are here to help and make your payment experience as smooth as possible!   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 true_response  \\\n0                                                                                                                                                                                                                                                                                                                           DELIVERY: can ya show me when my purchase is gonna arrive Positively! We understand your curiosity about the expected arrival time of your purchase. To assist you promptly, could you please provide the {{Order Number}} or {{Tracking Number}} associated with your purchase? With this information, we'll be able to provide you with an accurate estimate of the delivery date. Your patience is greatly appreciated as we work to provide you with the information you need.   \n1                                                                                                                       FEEDBACK: I'm not happy with ur work how do i make a claim I'm aware that you're feeling dissatisfied with our work, and I apologize for any inconvenience caused. Your feedback is crucial to us, and I want to ensure that your concern is addressed promptly and effectively. To make a claim, I recommend reaching out to our customer support team. They are available {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. They will guide you through the process and provide the necessary assistance. We appreciate your patience and understanding and look forward to resolving this matter for you.   \n2                                                                                                                                                                                                                                                                                                                                                           ORDER: I don't know how I can order some of your product We're here to help and expressing your interest in ordering some of our products! I'm here to guide you through the process step by step, so you can easily place your order. To get started, could you please provide me with the specific product(s) you would like to order? Once I have that information, I'll be able to assist you further and ensure a smooth ordering experience.   \n3                                                                                                                                   CONTACT: I need help chatting with an operator Your message means a lot! I'm aligned with the idea that you're seeking assistance with chatting with an operator. Our team of dedicated operators is here to help you with any questions or concerns you may have. To connect you with the right operator, could you please provide some more details about the specific topic or issue you need assistance with? This will enable us to ensure that you receive the most accurate and personalized support. While we gather the necessary information, please know that we appreciate your patience and are committed to providing you with the best possible assistance.   \n4  PAYMENT: can you tell me what payment options are available? I'll do my best! I'd be happy to provide you with information on our available payment options. At our company, we strive to offer a wide variety of payment methods to ensure convenience for our valued customers. Currently, we accept major credit and debit cards such as Visa, Mastercard, and American Express. We also offer the option to pay through popular online platforms like PayPal, Apple Pay, and Google Wallet. Additionally, we provide the facility for bank transfers, allowing you to make direct payments from your bank account. If you have any further questions or need assistance with any specific payment method, feel free to ask. We are here to help and make your payment experience as smooth as possible!   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             predicted_response  \\\n0                                                                                                                                                                                                                                                                                                                                                 question: DELIVERY: can ya show me when my purchase is gonna arrive Positively! We understand your curiosity about the expected arrival time of your purchase. To assist you promptly, could you please provide the {{Order Number}} or {{Tracking Number}} associated with your purchase? With this information, we'll be able to provide you with an accurate estimate of the delivery date. Your patience is greatly appreciated as we work to provide you with the information you need. Rest assured, we're here to support you every step of the way. Thank you for bringing this to our attention, and we appreciate your patience as we work towards resolving this matter for you. Your satisfaction is our top priority, and we're committed to ensuring a seamless experience for all our customers. Let's make this process as smooth as possible for you! We appreciate your patience as we work towards resolving this matter for you. Your satisfaction is our top priority, and we're committed to ensuring a   \n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             question: FEEDBACK: I'm not happy with ur work how do i make a claim I'm aware that you're feeling dissatisfied with our work, and I apologize for any inconvenience caused. Your feedback is crucial to us, and I want to ensure that your concern is addressed promptly and effectively. To make a claim, I recommend reaching out to our customer support team. They are available {{Customer Support Hours}} at {{Customer Support Phone Number}} or through the Live Chat on our website at {{Website URL}}. They will guide you through the process and provide the necessary assistance. We appreciate your patience and understanding and look forward to resolving this matter for you. If you have any further questions or need further assistance, please don't hesitate to let me know. I'm here to help you every step of the way!\"   \n2                                                                                                                                                                                                                                                                                                                                                                                                             question: ORDER: I don't know how I can order some of your product We're here to help and expressing your interest in ordering some of our products! I'm here to guide you through the process step by step, so you can easily place your order. To get started, could you please provide me with the specific product(s) you would like to order? Once I have that information, I'll be able to assist you further and ensure a smooth ordering experience. Thank you for bringing this to our attention, and we appreciate your patience as we work together to resolve this matter for you. Your satisfaction is our top priority, and we want to ensure a seamless ordering experience for you. Rest assured, we are here to support you every step of the way. If you have any further questions or need further assistance, please don't hesitate to let me know. I'm here to help you every step of the way. Your satisfaction is our top priority, and we   \n3                                                                                                                                                                                                       question: CONTACT: I need help chatting with an operator Your message means a lot! I'm aligned with the idea that you're seeking assistance with chatting with an operator. Our team of dedicated operators is here to help you with any questions or concerns you may have. To connect you with the right operator, could you please provide some more details about the specific topic or issue you need assistance with? This will enable us to ensure that you receive the most accurate and personalized support. While we gather the necessary information, please know that we appreciate your patience and are committed to providing you with the best possible assistance. If you have any further questions or need further assistance, please don't hesitate to let me know. I'm here to help you every step of the way! Could you please let me know if there's anything else I can assist you with? Your satisfaction is our top priority, and I'm here to assist you every step of the way. Thank you for bringing this matter to our attention, and we'll do everything we can to resolve it for you. We appreciate your patience and cooperation as we   \n4  question: PAYMENT: can you tell me what payment options are available? I'll do my best! I'd be happy to provide you with information on our available payment options. At our company, we strive to offer a wide variety of payment methods to ensure convenience for our valued customers. Currently, we accept major credit and debit cards such as Visa, Mastercard, and American Express. We also offer the option to pay through popular online platforms like PayPal, Apple Pay, and Google Wallet. Additionally, we provide the facility for bank transfers, allowing you to make direct payments from your bank account. If you have any further questions or need assistance with any specific payment method, feel free to ask. We are here to help and make your payment experience as smooth as possible! To get started, could you please provide me with more details about your specific payment options? This will allow me to guide you through the process and ensure a seamless payment experience for you. Thank you for bringing this to our attention, and we appreciate your patience as we work towards resolving this matter for you. Your satisfaction is our top priority, and we are committed to ensuring a seamless payment experience for all our valued customers. Let me know if there's anything else I can assist you with! Your feedback   \n\n       bleu  \\\n0  0.477305   \n1  0.798155   \n2  0.469467   \n3  0.543511   \n4  0.593550   \n\n                                                                                                                         rouge  \\\n0  {'rouge1': 0.6229508196721312, 'rouge2': 0.6198347107438016, 'rougeL': 0.6229508196721312, 'rougeLsum': 0.6229508196721312}   \n1                             {'rouge1': 0.8828125, 'rouge2': 0.8818897637795275, 'rougeL': 0.8828125, 'rougeLsum': 0.8828125}   \n2  {'rouge1': 0.6486486486486487, 'rouge2': 0.6459143968871595, 'rougeL': 0.6486486486486487, 'rougeLsum': 0.6486486486486487}   \n3  {'rouge1': 0.7028753993610224, 'rouge2': 0.7009646302250804, 'rougeL': 0.7028753993610224, 'rougeLsum': 0.7028753993610224}   \n4  {'rouge1': 0.7394957983193278, 'rouge2': 0.7380281690140845, 'rougeL': 0.7394957983193278, 'rougeLsum': 0.7394957983193278}   \n\n   bertscore  \n0   0.942220  \n1   0.976255  \n2   0.949062  \n3   0.958771  \n4   0.961740  \n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
